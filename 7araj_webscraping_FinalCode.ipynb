{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from random import randint\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# getting all the posts of certain car for certain model and given year\n",
    "\n",
    "# url = 'https://haraj.com.sa/tags/%D8%A7%D9%83%D9%88%D8%B1%D8%AF%202018' #accord 2018\n",
    "# url2 = 'https://haraj.com.sa/tags/الرياض_CX9%202019' #CX-9 2019\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get('https://haraj.com.sa/tags/CX9%202019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "request.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML = request.text\n",
    "# HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "r= requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')\n",
    "table= soup.find_all('div', attrs={'class':'adsx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table2=table[0].contents\n",
    "# table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver=webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('./chromedriver')\n",
    "\n",
    "def scroll_down(driver, lim = 200):\n",
    "    \"\"\"A method for scrolling the page.\"\"\"\n",
    "\n",
    "    # Get scroll height.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight - 1000\")\n",
    "    \n",
    "    counter = 0 \n",
    "    while counter < lim :\n",
    "        \n",
    "\n",
    "        # Scroll down to the bottom.\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight - 1000);\")\n",
    "\n",
    "        # Wait to load the page.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight - 1000\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "driver.get('https://haraj.com.sa/tags/CX9%202019')\n",
    "soup=BeautifulSoup(driver.page_source)\n",
    "elem = driver.find_element_by_xpath('//*[@id=\"AJAXloaded\"]/div/ul[1]')\n",
    "elem.click()\n",
    "\n",
    "scroll_down(driver)\n",
    "\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "titles = []\n",
    "dates = []\n",
    "city = []\n",
    "for i in soup.find_all('div', attrs={'class':'adxInfo'}):\n",
    "    lst.append(i.find('a')[\"href\"])\n",
    "    titles.append(i.find('a').text)\n",
    "    extra = i.find_all(\"div\", {\"class\" : \"adxExtraInfo\"})\n",
    "    dates.append(extra[0].find_all(\"div\", {\"class\" : \"adxExtraInfoPart\"})[1].text.strip())\n",
    "    city.append(extra[1].find_all(\"div\", {\"class\" : \"adxExtraInfoPart\"})[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 161, 161, 161)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city), len(titles), len(dates), len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_text = []\n",
    "for site in lst :\n",
    "    req = requests.get(site)\n",
    "    soup_ = BeautifulSoup(req.text,'html.parser')\n",
    "    desc = soup_.find('div', attrs={'class':'adxBody'})\n",
    "    lst_text.append(desc.text)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some trails to check!\n",
    "\n",
    "# lst_text[20]\n",
    "# len(lst_text)\n",
    "# print (lst[1])\n",
    "# titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post date</th>\n",
       "      <th>city</th>\n",
       "      <th>Full descriptipon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D لصيانة مازدا وجيلي</td>\n",
       "      <td>قبل  يوم و 6 ساعه</td>\n",
       "      <td>أبها</td>\n",
       "      <td>\\n\\t\\tمركز متخصص فقط في صيانة مازدا وجيلي وبيج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الاحساء -   مازدا 2019 فل ما</td>\n",
       "      <td>قبل  يوم و 9 ساعه</td>\n",
       "      <td>الشرقيه</td>\n",
       "      <td>\\n\\t\\tمطلوب مازدا 2019 فل ما تحت السقنتشرز \\nف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مازدا 2019</td>\n",
       "      <td>قبل  يوم و 16 ساعه</td>\n",
       "      <td>القصيم</td>\n",
       "      <td>\\n\\t\\tمازدا فل كامل ماشيه 32800 نظيفة شرط عليه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mazda CX-9  2019</td>\n",
       "      <td>قبل  يوم و 23 ساعه</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>\\n\\t\\tمازدا 2019 \\nفل كامل \\nالممشى 23 الف \\nا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>للبيع جنوط فل مازدا CX9 عدد 4 موديل 2019</td>\n",
       "      <td>قبل  يوم و 23 ساعه</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>\\n\\t\\tللبيع جنوط مازدا فل كامل CX9عدد 4 موديل ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title           post date     city  \\\n",
       "0                     3D لصيانة مازدا وجيلي   قبل  يوم و 6 ساعه     أبها   \n",
       "1              الاحساء -   مازدا 2019 فل ما   قبل  يوم و 9 ساعه  الشرقيه   \n",
       "2                                مازدا 2019  قبل  يوم و 16 ساعه   القصيم   \n",
       "3                          Mazda CX-9  2019  قبل  يوم و 23 ساعه   الرياض   \n",
       "4  للبيع جنوط فل مازدا CX9 عدد 4 موديل 2019  قبل  يوم و 23 ساعه   الرياض   \n",
       "\n",
       "                                   Full descriptipon  \n",
       "0  \\n\\t\\tمركز متخصص فقط في صيانة مازدا وجيلي وبيج...  \n",
       "1  \\n\\t\\tمطلوب مازدا 2019 فل ما تحت السقنتشرز \\nف...  \n",
       "2  \\n\\t\\tمازدا فل كامل ماشيه 32800 نظيفة شرط عليه...  \n",
       "3  \\n\\t\\tمازدا 2019 \\nفل كامل \\nالممشى 23 الف \\nا...  \n",
       "4  \\n\\t\\tللبيع جنوط مازدا فل كامل CX9عدد 4 موديل ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'title': titles, \n",
    "                   'post date': dates,\n",
    "                 'city': city,\n",
    "                    'Full descriptipon':lst_text,\n",
    "                   \n",
    "                  })\n",
    "df.head()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# df.to_csv(r'Path where you want to store the exported CSV file\\File Name.csv')\n",
    "df.to_csv(r'/Users/Abubattal/Desktop/DSI/projects/project-3/CX9_2019_F.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elentra = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
